{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Создание чат-бота-\"барахольщика\": по продуктовому запрос он будет рекомендовать товары, по остальным запросам он бует отвечать \"болталкой\" без фолбека."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Обучить классификатор: продуктовый запрос vs. всё остальное (продуктовым можно считать запрос, который равен названию или описанию товара).\n",
    "* добавить логику поиска похожих товаров по продуктовому запросу.\n",
    "* Вся логика должна быть завёрнута в метод get_answer(). Ответ на продуктовый запрос должен иметь вид \"product_id title\".\n",
    "\n",
    "Автотесты применяются к методу get_answer и проверяют несколько базовых сценариев:\n",
    "\n",
    " \n",
    " - assert(get_answer(“Юбка детская ORBY”).startswith(“58e3cfe6132ca50e053f5f82”))\n",
    " - assert(not get_answer(“Где ключи от танка”).startswith(“5”)) \n",
    "\n",
    "\n",
    "КРИТЕРИИ ПРОВЕРКИ:\n",
    "\n",
    "* Обучен классификатор «товарный запрос vs. болталка»:\n",
    "\n",
    "* Осуществлён препроцессинг текста (как минимум удаление знаков препинания, приведение к нижнему регистру, стемминг/лемматизация).\n",
    "* Текст векторизирован любым из изученных способов (CountVectorizer, TfidfVectorizer, HashingVectorizer, Word2Vec).\n",
    "* Выборка разделена на обучающую и валидационную.\n",
    "* Обучен классификатор с расчётом метрик на валидации (любое семейство алгоритмов, но предпочтительнее просто логистическая регрессия).\n",
    "* Модель сохранена и при применении загружается из pkl-файла (или аналога).\n",
    "\n",
    "\n",
    "→ Реализован поиск похожих товаров в контентной части бота\n",
    "\n",
    "* Все названия товаров свёрнуты в векторное представление Word2Vec (предобученном или обученном на исходном датасете).\n",
    "* Построен индекс по названиям документов.\n",
    "* Для товарных запросов реализован поиск в индексе (запрос также оборачивается Word2Vec, происходит проход в индекс).\n",
    "\n",
    "→ Реализована болталка\n",
    "\n",
    "* Все вопросы из датасета свёрнуты Word2Vec в векторное представление.\n",
    "* Построен индекс по вопросам.\n",
    "* На запрос в болталку происходит поиск ближайшего вопроса и возвращается ответ на этот вопрос."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data  \n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "\n",
    "# text \n",
    "import string \n",
    "import pymorphy2\n",
    "import codecs\n",
    "from stop_words import get_stop_words\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "\n",
    "# models\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import linear_model, metrics\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn import model_selection  \n",
    "\n",
    "# serialization \n",
    "import pickle \n",
    "\n",
    "# Index  \n",
    "import annoy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Очистка от пунктуации \n",
    "punctuation = set(string.punctuation)\n",
    "\n",
    "# стоп слова\n",
    "stop_words = set(get_stop_words('ru'))\n",
    "\n",
    "# лемматизация \n",
    "morpher = pymorphy2.MorphAnalyzer()\n",
    "\n",
    "def preprocess_text(line):\n",
    "    '''Text cleaning from punctuation, \n",
    "    register unification, returning normal form, excluding stop words'''\n",
    "    item = str(line)\n",
    "    item = ''.join(i for i in line.strip() if i not in punctuation).split()\n",
    "    item = [morpher.parse(i.lower())[0].normal_form for i in item]\n",
    "    item = [i for i in item if i not in stop_words and i != \"\"]\n",
    "    item = ' '.join(item)\n",
    "    return item\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# работает для продуктового запроса\n",
    "def get_answer(question):\n",
    "    \"\"\"Function preprocesses question text, composing a vector of question \n",
    "    as a sum of vectors for each word in question, \n",
    "    then finds out a nearest vector of reply and returns it's word representation\"\"\"\n",
    "    preprocessed_question = preprocess_text(question) \n",
    "    n_w2v = 0\n",
    "    vector = np.zeros(100)\n",
    "    for word in preprocessed_question:\n",
    "        if word in model_w2v_prod.wv:\n",
    "            vector += model_w2v_prod.wv[word]\n",
    "            n_w2v += 1\n",
    "    if n_w2v > 0:\n",
    "        vector = vector / n_w2v\n",
    "    answer_index = index_prod.get_nns_by_vector(vector, 1)\n",
    "    return index_map_prod[answer_index[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_answer(question):\n",
    "    \"\"\"Function preprocesses question text, composing a vector of question \n",
    "    as a sum of vectors for each word in question, \n",
    "    then finds out a nearest vector of reply and returns it's word representation\"\"\"\n",
    "    \n",
    "    preprocessed_question = preprocess_text(question) \n",
    "    \n",
    "    with open('classifier.pkl', 'rb') as pkl_file: \n",
    "        classifier = pickle.load(pkl_file) # loading \n",
    "        vec = ngrams_vectorizer.transform([preprocessed_question])\n",
    "        label = int(classifier.predict(vec))\n",
    "    \n",
    "    n_w2v = 0\n",
    "    vector = np.zeros(100)\n",
    "    \n",
    "    if label == 1: # проход в продуктовый индекс\n",
    "        for word in preprocessed_question:\n",
    "            if word in model_w2v_prod.wv:\n",
    "                vector += model_w2v_prod.wv[word]\n",
    "                n_w2v += 1\n",
    "        if n_w2v > 0:\n",
    "            vector = vector / n_w2v\n",
    "        answer_index = index_prod.get_nns_by_vector(vector, 1)\n",
    "        return index_map_prod[answer_index[0]]\n",
    "    \n",
    "    else: # проход в индекс болталки\n",
    "        for word in preprocessed_question:\n",
    "            if word in chat_model.wv:\n",
    "                vector += chat_model.wv[word]\n",
    "                n_w2v += 1\n",
    "        if n_w2v > 0:\n",
    "            vector = vector / n_w2v\n",
    "        answer_index = index.get_nns_by_vector(vector, 1)\n",
    "        return index_map[answer_index[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_accuracy(classifier, feature_vec_train, label, feature_vec_val):\n",
    "    \"\"\"Function fits a model on feature vectors \n",
    "    given and returns accuracy score\"\"\"\n",
    "    classifier.fit(feature_vec_train, label)\n",
    "    predictions = classifier.predict(feature_vec_val)     \n",
    "    return metrics.accuracy_score(predictions, y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>descrirption</th>\n",
       "      <th>product_id</th>\n",
       "      <th>category_id</th>\n",
       "      <th>subcategory_id</th>\n",
       "      <th>properties</th>\n",
       "      <th>image_links</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Юбка детская ORBY</td>\n",
       "      <td>Новая, не носили ни разу. В реале красивей чем...</td>\n",
       "      <td>58e3cfe6132ca50e053f5f82</td>\n",
       "      <td>22.0</td>\n",
       "      <td>2211</td>\n",
       "      <td>{'detskie_razmer_rost': '81-86 (1,5 года)'}</td>\n",
       "      <td>http://cache3.youla.io/files/images/360_360/58...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ботильоны</td>\n",
       "      <td>Новые,привезены из Чехии ,указан размер 40,но ...</td>\n",
       "      <td>5667531b2b7f8d127d838c34</td>\n",
       "      <td>9.0</td>\n",
       "      <td>902</td>\n",
       "      <td>{'zhenskaya_odezhda_tzvet': 'Зеленый', 'visota...</td>\n",
       "      <td>http://cache3.youla.io/files/images/360_360/5b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Брюки</td>\n",
       "      <td>Размер 40-42. Брюки почти новые - не знаю как ...</td>\n",
       "      <td>59534826aaab284cba337e06</td>\n",
       "      <td>9.0</td>\n",
       "      <td>906</td>\n",
       "      <td>{'zhenskaya_odezhda_dzhinsy_bryuki_tip': 'Брюк...</td>\n",
       "      <td>http://cache3.youla.io/files/images/360_360/59...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Продам детские шапки</td>\n",
       "      <td>Продам шапки,кажда 200р.Розовая и белая проданны.</td>\n",
       "      <td>57de544096ad842e26de8027</td>\n",
       "      <td>22.0</td>\n",
       "      <td>2217</td>\n",
       "      <td>{'detskie_pol': 'Девочкам', 'detskaya_odezhda_...</td>\n",
       "      <td>http://cache3.youla.io/files/images/360_360/57...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Блузка</td>\n",
       "      <td>Темно-синяя, 42 размер,состояние отличное,как ...</td>\n",
       "      <td>5ad4d2626c86cb168d212022</td>\n",
       "      <td>9.0</td>\n",
       "      <td>907</td>\n",
       "      <td>{'zhenskaya_odezhda_tzvet': 'Синий', 'zhenskay...</td>\n",
       "      <td>http://cache3.youla.io/files/images/360_360/5a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35543</th>\n",
       "      <td>Юбка</td>\n",
       "      <td>Юбка Белая по.Турция фирма adL</td>\n",
       "      <td>5b5f181c62e1c6616a7f6472</td>\n",
       "      <td>9.0</td>\n",
       "      <td>904</td>\n",
       "      <td>{'zhenskaya_odezhda_platya_yubki_tip': 'Юбки',...</td>\n",
       "      <td>http://cache3.youla.io/files/images/360_360/5b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35544</th>\n",
       "      <td>Новый твидовый пиджак</td>\n",
       "      <td>Новый с бирками пиджак размер S в стиле Coco C...</td>\n",
       "      <td>5bd6c8b29e94ba033d31f8d0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>908</td>\n",
       "      <td>{'brand_zhenskii': 'Chanel', 'zhenskaya_odezhd...</td>\n",
       "      <td>http://cache3.youla.io/files/images/360_360/5b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35545</th>\n",
       "      <td>Женская зимняя куртка</td>\n",
       "      <td>Женская зимняя спортивная куртка фирмы Rossiqn...</td>\n",
       "      <td>5bd6c8bc074b3e1c056f69b2</td>\n",
       "      <td>9.0</td>\n",
       "      <td>903</td>\n",
       "      <td>{'zhenskaya_odezhda_razmer': '48-50 (XL)', 'zh...</td>\n",
       "      <td>http://cache3.youla.io/files/images/360_360/5b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35546</th>\n",
       "      <td>Новая золотая ветровка</td>\n",
       "      <td>Женская ветровка размер 44-46. Цвет приглушённ...</td>\n",
       "      <td>5bd6c8fb2138bbc55745362c</td>\n",
       "      <td>9.0</td>\n",
       "      <td>903</td>\n",
       "      <td>{'zhenskaya_odezhda_razmer': '44-46 (М)', 'zhe...</td>\n",
       "      <td>http://cache3.youla.io/files/images/360_360/5b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35547</th>\n",
       "      <td>Шарф</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5bd6c8fbaaab283b79142a1f</td>\n",
       "      <td>9.0</td>\n",
       "      <td>914</td>\n",
       "      <td>{'zhenskaya_odezhda_aksessuary_tip': 'Шарфы и ...</td>\n",
       "      <td>http://cache3.youla.io/files/images/360_360/5b...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>35548 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                        title  \\\n",
       "0           Юбка детская ORBY   \n",
       "1                   Ботильоны   \n",
       "2                       Брюки   \n",
       "3        Продам детские шапки   \n",
       "4                      Блузка   \n",
       "...                       ...   \n",
       "35543                    Юбка   \n",
       "35544   Новый твидовый пиджак   \n",
       "35545   Женская зимняя куртка   \n",
       "35546  Новая золотая ветровка   \n",
       "35547                    Шарф   \n",
       "\n",
       "                                            descrirption  \\\n",
       "0      Новая, не носили ни разу. В реале красивей чем...   \n",
       "1      Новые,привезены из Чехии ,указан размер 40,но ...   \n",
       "2      Размер 40-42. Брюки почти новые - не знаю как ...   \n",
       "3      Продам шапки,кажда 200р.Розовая и белая проданны.   \n",
       "4      Темно-синяя, 42 размер,состояние отличное,как ...   \n",
       "...                                                  ...   \n",
       "35543                     Юбка Белая по.Турция фирма adL   \n",
       "35544  Новый с бирками пиджак размер S в стиле Coco C...   \n",
       "35545  Женская зимняя спортивная куртка фирмы Rossiqn...   \n",
       "35546  Женская ветровка размер 44-46. Цвет приглушённ...   \n",
       "35547                                                NaN   \n",
       "\n",
       "                     product_id  category_id subcategory_id  \\\n",
       "0      58e3cfe6132ca50e053f5f82         22.0           2211   \n",
       "1      5667531b2b7f8d127d838c34          9.0            902   \n",
       "2      59534826aaab284cba337e06          9.0            906   \n",
       "3      57de544096ad842e26de8027         22.0           2217   \n",
       "4      5ad4d2626c86cb168d212022          9.0            907   \n",
       "...                         ...          ...            ...   \n",
       "35543  5b5f181c62e1c6616a7f6472          9.0            904   \n",
       "35544  5bd6c8b29e94ba033d31f8d0          9.0            908   \n",
       "35545  5bd6c8bc074b3e1c056f69b2          9.0            903   \n",
       "35546  5bd6c8fb2138bbc55745362c          9.0            903   \n",
       "35547  5bd6c8fbaaab283b79142a1f          9.0            914   \n",
       "\n",
       "                                              properties  \\\n",
       "0            {'detskie_razmer_rost': '81-86 (1,5 года)'}   \n",
       "1      {'zhenskaya_odezhda_tzvet': 'Зеленый', 'visota...   \n",
       "2      {'zhenskaya_odezhda_dzhinsy_bryuki_tip': 'Брюк...   \n",
       "3      {'detskie_pol': 'Девочкам', 'detskaya_odezhda_...   \n",
       "4      {'zhenskaya_odezhda_tzvet': 'Синий', 'zhenskay...   \n",
       "...                                                  ...   \n",
       "35543  {'zhenskaya_odezhda_platya_yubki_tip': 'Юбки',...   \n",
       "35544  {'brand_zhenskii': 'Chanel', 'zhenskaya_odezhd...   \n",
       "35545  {'zhenskaya_odezhda_razmer': '48-50 (XL)', 'zh...   \n",
       "35546  {'zhenskaya_odezhda_razmer': '44-46 (М)', 'zhe...   \n",
       "35547  {'zhenskaya_odezhda_aksessuary_tip': 'Шарфы и ...   \n",
       "\n",
       "                                             image_links  \n",
       "0      http://cache3.youla.io/files/images/360_360/58...  \n",
       "1      http://cache3.youla.io/files/images/360_360/5b...  \n",
       "2      http://cache3.youla.io/files/images/360_360/59...  \n",
       "3      http://cache3.youla.io/files/images/360_360/57...  \n",
       "4      http://cache3.youla.io/files/images/360_360/5a...  \n",
       "...                                                  ...  \n",
       "35543  http://cache3.youla.io/files/images/360_360/5b...  \n",
       "35544  http://cache3.youla.io/files/images/360_360/5b...  \n",
       "35545  http://cache3.youla.io/files/images/360_360/5b...  \n",
       "35546  http://cache3.youla.io/files/images/360_360/5b...  \n",
       "35547  http://cache3.youla.io/files/images/360_360/5b...  \n",
       "\n",
       "[35548 rows x 7 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_product = pd.read_csv('ProductsDataset.csv')\n",
    "data_product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "title                0\n",
       "descrirption      2011\n",
       "product_id          12\n",
       "category_id         12\n",
       "subcategory_id      12\n",
       "properties          12\n",
       "image_links         15\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_product.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filling misses in id of products with \"no id\" \n",
    "data_product['product_id'] = data_product['product_id'].fillna('no id')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question classifying"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обучить классификатор: продуктовый запрос vs. всё остальное (продуктовым можно считать запрос, который равен названию или описанию товара)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для классификатора запросов объединим данные: \n",
    " - с названием товаров\n",
    " - и ответы на вопросы для чата. \n",
    "\n",
    "И добавим target - метку, 1 - для товаров, 0 - для вопросов чата\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Товарные данные \n",
    "data = {'issue': data_product.title, 'target': 1}\n",
    "data = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# данные из болталки для обучения \n",
    "sentences = []\n",
    "\n",
    "# morpher = pymorphy2.MorphAnalyzer()\n",
    "# sw = set(get_stop_words(\"ru\"))\n",
    "# exclude = set(string.punctuation)\n",
    "c = 0\n",
    "\n",
    "with codecs.open(\"Otvety.txt\", \"r\", \"utf-8\") as fin:\n",
    "    for line in fin:\n",
    "        item = preprocess_text(line)\n",
    "        sentences.append(item)\n",
    "        c += 1\n",
    "        if c > 35549:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_chat = {'issue': sentences, 'target': 0}\n",
    "data_chat = pd.DataFrame(data_chat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# сформируем фрейм для обучения классификатора, с сбалансированными классами \n",
    "df = pd.concat([data, data_chat], axis=0, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    35550\n",
       "1    35548\n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.target.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>issue</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>35548</th>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35549</th>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35550</th>\n",
       "      <td>вопрос тдв отдыхать лично советовать завести</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35551</th>\n",
       "      <td>хомячок</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35552</th>\n",
       "      <td>мужик йопарить собачка 50 кошка</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71093</th>\n",
       "      <td>саров 10р</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71094</th>\n",
       "      <td>череповец вологда 10 рубль</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71095</th>\n",
       "      <td>автобус 10 руб траллейбус трамвай 6 руб маршру...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71096</th>\n",
       "      <td>50 деревяшекалматы</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71097</th>\n",
       "      <td>увожать дед пыхтогород новосибирск стоимость п...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>35550 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   issue  target\n",
       "35548                                                          0\n",
       "35549                                                          0\n",
       "35550       вопрос тдв отдыхать лично советовать завести       0\n",
       "35551                                            хомячок       0\n",
       "35552                    мужик йопарить собачка 50 кошка       0\n",
       "...                                                  ...     ...\n",
       "71093                                          саров 10р       0\n",
       "71094                         череповец вологда 10 рубль       0\n",
       "71095  автобус 10 руб траллейбус трамвай 6 руб маршру...       0\n",
       "71096                                 50 деревяшекалматы       0\n",
       "71097  увожать дед пыхтогород новосибирск стоимость п...       0\n",
       "\n",
       "[35550 rows x 2 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df.target == 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## data split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# splitting data \n",
    "x_train, x_val, y_train, y_val= model_selection.train_test_split(df['issue'], df['target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = np.array(y_train)\n",
    "y_val = np.array(y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tfidf vectorizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# попробуем тфидф векторнуть и на этом обучить логрег\n",
    "tfidf_vectorizer = TfidfVectorizer().fit(x_train.values) \n",
    "x_train_tfidf = tfidf_vectorizer.transform(x_train)\n",
    "x_valid_tfidf = tfidf_vectorizer.transform(x_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Count vectorizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_vectorizer = CountVectorizer().fit(x_train.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_count = count_vectorizer.transform(x_train)\n",
    "x_valid_count = count_vectorizer.transform(x_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### tfIdf n-grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "ngrams_vectorizer = TfidfVectorizer(ngram_range=(1, 3)).fit(x_train.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_ngrams = ngrams_vectorizer.transform(x_train)\n",
    "x_valid_ngrams = ngrams_vectorizer.transform(x_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Зимний костюм Tokka Tribe 98 р-р', 'Ветровка летняя',\n",
       "       'Интересное платье с цветным принтом,50 размер.', ...,\n",
       "       'Замок игрушечный', 'Новое платье Next 2-6 мес.',\n",
       "       'генералка хозяин временный ввоз кататься'], dtype=object)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = LogisticRegression()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Metrics \n",
    "Метрикой возьмем accuracy, так как классы по target сбалансированы."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy, Count Vectors:  0.9686638537271449\n",
      "accuracy, WordLevel TF-IDF:  0.9688326300984529\n",
      "accuracy, N-Gram Vectors:  0.9684388185654008\n"
     ]
    }
   ],
   "source": [
    "# Linear Classifier на Count Vectors\n",
    "accuracy = model_accuracy(clf, x_train_count, y_train, x_valid_count)\n",
    "print(\"accuracy, Count Vectors: \", accuracy)\n",
    "\n",
    "# Linear Classifier на Word Level TF IDF Vectors\n",
    "accuracy = model_accuracy(clf, x_train_tfidf, y_train, x_valid_tfidf)\n",
    "print(\"accuracy, WordLevel TF-IDF: \", accuracy)\n",
    "\n",
    "# Linear Classifier на Ngram Level TF IDF Vectors\n",
    "accuracy = model_accuracy(clf, x_train_ngrams, y_train, x_valid_ngrams)\n",
    "print(\"accuracy, N-Gram Vectors: \", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "regressor = clf.fit(x_train_ngrams, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Classifier test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "issue = 'юбка детская Orby'\n",
    "vec = ngrams_vectorizer.transform([issue])\n",
    "label = regressor.predict(vec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Classifier saving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('classifier.pkl', 'wb') as output: \n",
    "    pickle.dump(regressor, output) # saving     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Content\n",
    "Реализован поиск похожих товаров в контентной части бота\n",
    "\n",
    " - Все названия товаров свёрнуты в векторное представление Word2Vec (предобученном или обученном на исходном датасете).\n",
    " - Построен индекс по названиям документов.\n",
    " - Для товарных запросов реализован поиск в индексе (запрос также оборачивается Word2Vec, происходит проход в индекс)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для векторизации нам нужно будет поместить целевую - id продукта - в контекст запроса. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0             58e3cfe6132ca50e053f5f82\\t Юбка детская ORBY\n",
       "1                     5667531b2b7f8d127d838c34\\t Ботильоны\n",
       "2                         59534826aaab284cba337e06\\t Брюки\n",
       "3          57de544096ad842e26de8027\\t Продам детские шапки\n",
       "4                        5ad4d2626c86cb168d212022\\t Блузка\n",
       "                               ...                        \n",
       "35543                      5b5f181c62e1c6616a7f6472\\t Юбка\n",
       "35544     5bd6c8b29e94ba033d31f8d0\\t Новый твидовый пиджак\n",
       "35545     5bd6c8bc074b3e1c056f69b2\\t Женская зимняя куртка\n",
       "35546    5bd6c8fb2138bbc55745362c\\t Новая золотая ветровка\n",
       "35547                      5bd6c8fbaaab283b79142a1f\\t Шарф\n",
       "Length: 35548, dtype: object"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "title_id = data_product['product_id'].astype(str) + '\\t ' + data_product['title'].astype(str)\n",
    "    \n",
    "title_id "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0             58e3cfe6132ca50e053f5f82 юбка детский orby\n",
       "1                      5667531b2b7f8d127d838c34 ботильон\n",
       "2                         59534826aaab284cba337e06 брюки\n",
       "3         57de544096ad842e26de8027 продать детский шапка\n",
       "4                        5ad4d2626c86cb168d212022 блузка\n",
       "                              ...                       \n",
       "35543                      5b5f181c62e1c6616a7f6472 юбка\n",
       "35544     5bd6c8b29e94ba033d31f8d0 новый твидовый пиджак\n",
       "35545     5bd6c8bc074b3e1c056f69b2 женский зимний куртка\n",
       "35546    5bd6c8fb2138bbc55745362c новый золотой ветровка\n",
       "35547                      5bd6c8fbaaab283b79142a1f шарф\n",
       "Length: 35548, dtype: object"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "title_id.apply(preprocess_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vectorizing, saving model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_w2v_prod = Word2Vec(sentences=title_id, vector_size=100, min_count=1, window=5)\n",
    "model_w2v_prod.save('model_w2v_prod')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Index \n",
    "Строим индекс по продуктовым запросам"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['58e3cfe6132ca50e053f5f82', ' Юбка детская ORBY']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = title_id[0].split('\\t')# [-1]\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index_prod = annoy.AnnoyIndex(100, 'angular')\n",
    "\n",
    "# строим словарь соответствия векторного представления буквенному\n",
    "index_map_prod = {} \n",
    "counter = 0\n",
    "\n",
    "for line in title_id:\n",
    "    n_w2v = 0\n",
    "    els = line.split('\\t')\n",
    "    index_map_prod[counter] = ' '. join(els)  # els\n",
    "    question = preprocess_text(line.split('\\t')[1])\n",
    "    vector = np.zeros(100)\n",
    "    for word in question:\n",
    "        if word in model_w2v_prod.wv:\n",
    "            vector += model_w2v_prod.wv[word]\n",
    "            n_w2v += 1\n",
    "    if n_w2v > 0:\n",
    "        vector = vector / n_w2v\n",
    "    index_prod.add_item(counter, vector)\n",
    "    \n",
    "    counter += 1\n",
    "    \n",
    "index_prod.build(10)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'58e3cfe6132ca50e053f5f82  Юбка детская ORBY'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question = 'юбка детская Orby'\n",
    "get_answer(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index_prod.save('prod_reply.ann')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chat\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - Все вопросы из датасета свёрнуты Word2Vec в векторное представление.\n",
    " - Построен индекс по вопросам.\n",
    " - На запрос в болталку происходит поиск ближайшего вопроса и возвращается ответ на этот вопрос."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "question = None\n",
    "written = False\n",
    "\n",
    "#Мы идем по всем записям, берем первую строку как вопрос\n",
    "# и после знака --- находим ответ\n",
    "with codecs.open(\"prepared_answers.txt\", \"w\", \"utf-8\") as fout:\n",
    "    with codecs.open(\"Otvety.txt\", \"r\", \"utf-8\") as fin:\n",
    "        for line in fin:\n",
    "            if line.startswith(\"---\"):\n",
    "                written = False\n",
    "                continue\n",
    "            if not written and question is not None:\n",
    "                fout.write(question.replace(\"\\t\", \" \").strip() + \"\\t\" + line.replace(\"\\t\", \" \"))\n",
    "                written = True\n",
    "                question = None\n",
    "                continue\n",
    "            if not written:\n",
    "                question = line.strip()\n",
    "                continue"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "sentences = []\n",
    "\n",
    "morpher = MorphAnalyzer()\n",
    "sw = set(get_stop_words(\"ru\"))\n",
    "exclude = set(string.punctuation)\n",
    "c = 0\n",
    "\n",
    "with open(\"Otvety.txt\", \"r\") as fin:\n",
    "    for line in tqdm_notebook(fin):\n",
    "        spls = preprocess_txt(line)\n",
    "        sentences.append(spls)\n",
    "        c += 1\n",
    "        if c > 500000:\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vectorizing, saving model  "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Обучим модель word2vec на наших вопросах\n",
    "sentences = [i for i in sentences if len(i) > 2]\n",
    "model = Word2Vec(sentences=sentences, vector_size=100, min_count=1, window=5)\n",
    "model.save(\"chat_model_l\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('chat_model_l.pkl', 'rb') as file: \n",
    "    chat_model = pickle.load(file)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Load pre-trained Word2Vec model.\n",
    "chat_model = Word2Vec.load(\"w2v_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<gensim.models.keyedvectors.KeyedVectors at 0x1e8e4052af0>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_model.wv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Index "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index = annoy.AnnoyIndex(100 ,'angular')\n",
    "\n",
    "index_map = {}\n",
    "counter = 0\n",
    "\n",
    "with codecs.open(\"prepared_answers.txt\", \"r\", \"utf-8\") as f:\n",
    "    for line in f:\n",
    "        n_w2v = 0\n",
    "        spls = line.split(\"\\t\")\n",
    "        index_map[counter] = spls[1]\n",
    "        question = preprocess_text(spls[0])\n",
    "        vector = np.zeros(100)\n",
    "        for word in question:\n",
    "            if word in chat_model.wv:\n",
    "                vector += chat_model.wv[word]\n",
    "                n_w2v += 1\n",
    "        if n_w2v > 0:\n",
    "            vector = vector / n_w2v\n",
    "        index.add_item(counter, vector)\n",
    "            \n",
    "        counter += 1\n",
    "\n",
    "index.build(10)\n",
    "#index.save('sp.ann')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "index = annoy.AnnoyIndex(100, 'angular')\n",
    "index.load('sp.ann')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Autotests "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert(get_answer('Юбка детская ORBY').startswith('58e3cfe6132ca50e053f5f82'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert(not get_answer('Где ключи от танка').startswith('5')) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'58e3cfe6132ca50e053f5f82  Юбка детская ORBY'"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question = \"юбка детская ORby\"\n",
    "get_answer(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Ща проверим!. \\n'"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question = 'где ключи от танка'\n",
    "get_answer(question)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thank you for attention, it was a real pleasure to share this project to you."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "258px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
